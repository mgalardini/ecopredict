#!/usr/bin/env python

__author__ = "Marco Galardini"
__version__ = '0.1.0'


def get_options():
    import argparse

    # create the top-level parser
    description = "Bootstrap the score by using random gene sets"
    parser = argparse.ArgumentParser(description=description,
                                     prog='overall_bootstrap_random_sets')

    parser.add_argument('probabilities', action='store',
                        help='Deleterious probabilities file')
    parser.add_argument('deletion', action='store',
                        help='Deletion experiment important genes (conditions -> genes)')
    parser.add_argument('delmatrix', action='store',
                        help='Deletion matrix (used to get gene names)')
    parser.add_argument('matrix', action='store',
                        help='EMAP matrix')
    parser.add_argument('fdr', action='store',
                        help='FDR matrix')

    parser.add_argument('--conversion', action='store',
                        default=None,
                        help='ECK to uniprot identifiers')
    parser.add_argument('--lconversion', action='store',
                        default=None,
                        help='Locus to uniprot identifiers')
    parser.add_argument('--uncommon', action='store',
                        default=None,
                        help='Genes to exclude from the gene sets')
    parser.add_argument('--pseudocount', action='store',
                        type=float,
                        default=0.01,
                        help='Pseudocount [Default: 0.01]')
    parser.add_argument('--bootstraps', action='store',
                        type=int,
                        default=1000,
                        help='Bootstraps [Default: 1000]')
    parser.add_argument('--fdr-threshold', action='store',
                        type=float,
                        default=0.05,
                        help='FDR threshold [Default: 0.05]')

    parser.add_argument('--version', action='version',
                        version='%(prog)s '+__version__)

    return parser.parse_args()


def prediction_auc(a, v, m):
    from sklearn.metrics import roc_curve, auc

    conditions = set()
    for c in m.columns:
        if c in a.columns:
            conditions.add(c)
    strains = {}
    mstrains = set(m.index)
    for c in conditions:
        strains[c] = {x for x in a[c].dropna().index if x in mstrains}

    true_values = []
    scores = []
    for c in conditions:
        for s in strains[c]:
            vvalue = v.loc[s][c]
            if vvalue < 0:
                t = True
            else:
                t = False
            mscore = m.loc[[x for x in m.index if x.startswith(s)]][c]
            for x in mscore:
                if np.isnan(x):
                    continue
                true_values.append(t)
                scores.append(x)
    
    fpr, tpr, thresholds = roc_curve(true_values, scores)
    roc_auc = auc(fpr, tpr)

    return roc_auc, tpr, fpr


def expected(values, pseudo):
    return sum(np.log(1 - values + pseudo))/values.shape[0]


def score(values, genes, pseudo):
    return sum(np.log(1 - values.loc[genes].dropna() + pseudo)/expected(values,
               pseudo))

if __name__ == "__main__":
    import random
    import numpy as np
    import pandas as pd

    options = get_options()

    # Read strains data
    a = pd.read_table(options.matrix)
    a.set_index(a.columns[0], inplace=True)
    # Load the FDR corrections to identify proper phenotypes
    f = pd.read_table(options.fdr)
    f.set_index(f.columns[0], inplace=True)

    # Apply the FDR correction
    v = a[f < options.fdr_threshold]

    conversion = {}
    if options.conversion:
        conversion = {x.split()[0]:x.rstrip().split()[1]
                      for x in open(options.conversion)}
    lconversion = {}
    if options.lconversion:
        lconversion = {x.split()[0]:x.rstrip().split()[1]
                       for x in open(options.lconversion)}
    uncommon = {}
    if options.uncommon:
        uncommon = {lconversion.get(x.rstrip(), x.rstrip())
                    for x in open(options.uncommon)}
    deletion = {x.split()[0]:{conversion.get(y.split('-')[0], y.split('-')[0])
                              for y in x.rstrip().split('\t')[1].split()
                              if conversion.get(y.split('-')[0], y.split('-')[0]) not in uncommon}
                for x in open(options.deletion)
                if len(x.split()) > 1}

    dm = pd.read_table(options.delmatrix)
    dm.set_index(dm.columns[0], inplace=True)
    dgenes = list({conversion.get(x.split('-')[0], x.split('-')[0])
                  for x in dm.index
                  if conversion.get(x.split('-')[0], x.split('-')[0]) not in uncommon})

    m = pd.read_table(options.probabilities)
    m.set_index(m.columns[0], inplace=True)
    m[np.isnan(m)] = 0.

    for i in range(options.bootstraps):
        # random gene sets with same numerosity
        rsets = {}
        for c in deletion:
            random.shuffle(dgenes)
            rsets[c] = {dgenes[x] for x in range(len(deletion[c]))}

        ps = []
        for k, genes in rsets.items():
            try:
                p = m.apply(score, genes=genes, pseudo=options.pseudocount)
                p = pd.DataFrame(p).T
                p.index = [k]
                ps.append(p)
            except KeyError:
                # Very rare, means that none of the genes was found
                continue
        s = pd.concat(ps)
        s.index.name = 'condition'
        s = s.T
 
        sauc, tpr, fpr = prediction_auc(a, v, s)
        for x, y in zip(tpr, fpr):
            print('%s\t%.5f\t%.5f\t%.5f' % (i,
                                            sauc,
                                            x, y))
